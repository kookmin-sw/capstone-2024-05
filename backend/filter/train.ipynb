{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "from data_preprocessing import Autodata\n",
    "from datasets import concatenate_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataloader import CustomDataset\n",
    "from utils import compute_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"monologg/koelectra-small-v3-discriminator\"\n",
    "data = Autodata(\"./data\")\n",
    "cfn_question = data.concat_dataset[\"question\"]\n",
    "normal_instruction_question = data.load_instruction_dataset(\"nlpai-lab/kullm-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_instruction_question = normal_instruction_question[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn_data = data.label_indexing(cfn_question, state=0)\n",
    "normal_instruction_data = data.label_indexing(normal_instruction_question, state=1)\n",
    "\n",
    "total_data = concatenate_datasets([cfn_data, normal_instruction_data])\n",
    "# train_dataset, val_dataset = train_test_split(\n",
    "#     total_data, test_size=0.2, random_state=42\n",
    "# )\n",
    "question = total_data[\"question\"]\n",
    "target = total_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_train, question_valid, target_train, target_valid = train_test_split(\n",
    "    question, target, test_size=0.2, random_state=42, stratify=target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BackupPlan 리소스 유형을 가진 백업 계획을 생성하는 템플릿을 만들어줘',\n",
       " 'Signaling Channel 생성 템플릿을 만들고 채널 이름을 UniqueChannelName으로 설정해줘, 태그는 environment를 key로 prod를 value로 설정해줘',\n",
       " '주어진 키워드로 스토리를 생성합니다.',\n",
       " 'Cognito IdentityPoolRoleAttachment 리소스를 IdentityPoolId를 region:guid 형식으로, authenticated와 unauthenticated역할을 설정해줘',\n",
       " '은유가 드러나도록 문장을 다시 작성합니다.',\n",
       " \"Elastic Beanstalk 애플리케이션의 configuration template을 만들어줘. 애플리케이션 이름을 MyApplication으로, 설명을 'Elastic Beanstalk configuration template example'로 설정하고, PHP 7.1 실행 환경을 사용해줘.\",\n",
       " '사용자 정보 집합이 주어지면 유효한 사용자 이름을 생성합니다.',\n",
       " '출근길에 건강한 간식을 추천합니다.',\n",
       " '주어진 회사의 로고를 디자인합니다.',\n",
       " '건강한 아침 식사를 위한 5가지 품목의 쇼핑 목록을 작성하세요.',\n",
       " 'Capacity Reservation Fleet 템플릿을 생성해줘. EndDate를 2023-12-31T23:59:59Z로 설정하고, NoRemoveEndDate가 false이며, RemoveEndDate도 false로 설정해줘.',\n",
       " \"HTTP API를 생성하려고 해. 이 API의 이름은 'ProductService', 프로토콜 타입은 'HTTP'로, 라우트 선택 표현식을 '${request.method} ${request.path}'로 설정해줘.\",\n",
       " 'Route53 RecordSetGroup을 만들어서 메일 서버의 A, MX, TXT 레코드를 각각 지정해줘. A 레코드는 IP 주소 \\'192.0.2.44\\'로 설정하고, MX 레코드는 \\'10 mail.example.com\\'으로, TXT 레코드는 \\'\"v=spf1 ip4:203.0.113.0/30 -all\"\\'로 설정해줘. 모든 레코드의 TTL은 \\'900\\'으로 설정하고, 이 모든 작업에 대한 설명으로 \\'Creating records for mail server\\'를 포함시켜줘.',\n",
       " '종이를 재활용하는 세 가지 방법을 제안하세요.',\n",
       " \"ECR 레포지토리에 대한 CloudFormation 템플릿을 만들어줘. 'dynamic-repo'라는 이름으로 생성하되, 이미지 태그가 불변하도록 설정해줘\",\n",
       " '다음 단어를 의미 있는 문장으로 구성하세요.',\n",
       " \"SageMaker NotebookInstanceLifecycleConfig 리소스를 생성하는 템플릿을 만들어줘. OnStart 시점에 'echo hello'를 실행하는 스크립트를 포함시켜줘\",\n",
       " \"SageMaker 프로젝트 생성을 위한 템플릿 만들기, 프로젝트의 이름을 'MLProject'로 설정하고 설명을 '기계학습 프로젝트'로 설정해줘.\",\n",
       " \"ApiGatewayManagedOverrides 리소스와 관련된 설정을 구성해줘. API 'api-12345'와 관련된 설정만 구성해줘\",\n",
       " '다음 진술이 사실인 이유를 설명하세요.',\n",
       " 'CloudFormation Hook 버전에 로깅 구성 정보를 포함하는 템플릿을 만들어줘',\n",
       " '다음 기사의 눈길을 사로잡는 재치 있는 헤드라인을 생각해 보세요.',\n",
       " '일련의 숫자가 주어지면 평균을 계산합니다.',\n",
       " 'RDS DB 프록시에서 TLS 요구하고, VPC 서브넷 ID를 subnet-01b761b31fb498f20, subnet-012b9a958ef0f9949로 설정하는 CloudFormation 템플릿을 만들어줘',\n",
       " '주어진 주제로 하이쿠시를 만들어 보세요.',\n",
       " '다음 관용구의 의미는 무엇인가요?',\n",
       " '건강한 아침 식사 아이디어 4가지 목록을 생성하세요.',\n",
       " '고객 만족도 측정을 위한 설문조사 질문 만들기',\n",
       " '모든 계정이 SQS SendMessage 액션을 사용할 수 있도록 하는 SQS 큐 정책을 만들어줘',\n",
       " \"Backup 보고 계획에 대하여, '사업부별 백업 보고서'라는 이름과 함께 S3 버킷을 배달 경로로 설정하고, 리소스 준수 보고서를 보고 팅셋으로 사용하는 템플릿 파일을 생성해줘.\",\n",
       " '갈릴레오 갈릴레이와 동시대에 살았던 유명한 인물 세 명을 말하세요.',\n",
       " \"Redshift 엔드포인트에 대한 엑세스를 관리하는 템플릿을 만들어줘. 클러스터 ID는 'cluster-1234', 엔드포인트 이름은 'endpoint-access-1234', 서브넷 그룹 이름은 'subnet-group-1234', VPC 보안 그룹 ID는 ['sg-11111', 'sg-22222']로 설정해줘\",\n",
       " '미국의 정부 직책 세 가지를 말하세요.',\n",
       " '클라우드포메이션으로 모듈의 기본 버전을 등록하는 템플릿을 만들어줘. 모듈 이름을 My::Sample::Test::MODULE로 설정하고, 모듈 패키지는 s3://my-sample-moduleversion-bucket/sample-module-package-v1.zip를 사용해줘',\n",
       " \"API Gateway에서 사용할 도메인 이름에 'mydomainame.us-east-1.com'을 설정하고, 엔드포인트 타입을 'REGIONAL', 인증서 ARN을 'arn:aws:acm:us-east-1:123456789012:certificate/1a2b3c4d-aaaa-aaaa-aaaa-1a2b3c4d5e6f'로 지정하여 도메인 이름을 생성해줘\",\n",
       " \"ECR 레지스트리에서 외부 public 레지스트리의 이미지를 캐시하기 위한 pull through cache rule 생성해줘. 저장소 접두사를 'sample-ecr'로, 상위 레지스트리 URL을 'external.ecr.com'으로 설정해줘\",\n",
       " '다음 문장을 다시 작성합니다:\\n\\n\"지원자는 동기 부여가 높은 개인입니다.\"',\n",
       " '소설에 등장하는 다음 인물들이 \"권력의 부패한 영향력\"이라는 주제를 어떻게 반영하고 있는지 나타내십시오.',\n",
       " 'Route53에서 KeySigningKey 생성이 필요해. HostedZoneId를 Z2A4B6C8D10E12, KeyManagementServiceArn를 arn:aws:kms:ap-southeast-1:888999000111:key/2b3c4d5e-6f7g-8h9i-0j1k-2lmnopq3r4s5, Name을 CustomKSK, Status를 DELETING으로 해서 만들어줘.',\n",
       " '지정된 제품에 대한 슬로건을 만듭니다.',\n",
       " \"Amazon Redshift 서브넷 그룹을 만들어줘. 설명은 'Production Subnet Group'으로 설정하고, 서브넷 아이디는 'subnet-12345678'과 'subnet-87654321'이야. 태그 없이 만들어줘\",\n",
       " '수요와 공급의 법칙에 따라 수요가 증가하면 재화의 가격이 어떻게 될지 설명하세요.',\n",
       " 'CloudTrail 채널에 연결할 리소스 기반 정책을 가진 CloudFormation 템플릿 만들어줘, 정책은 최대 20개의 문을 포함해야 하고, 각 문은 최대 50개의 원칙을 포함할 수 있어',\n",
       " '스톤월 봉기의 역사적 의미를 분석합니다.',\n",
       " '필드 레벨 암호화에 사용될 공개 키를 포함한 CloudFront의 리소스 생성 템플릿을 작성해줘',\n",
       " 'ECS 서비스에 대한 CloudFormation 템플릿 만들기, TaskDefinition을 myTaskDefinition으로, DesiredCount를 2로 설정',\n",
       " '호주에 140종이 넘는 뱀이 있는 이유를 가설로 세워보세요.',\n",
       " \"0.0.0.0/0 대상으로 인터넷 경로를 추가하고 모든 클라이언트 VPN 끝점의 트래픽을 VPC 서브넷 'subnet-12345'를 통해 경로 지정하는 템플릿을 제공해줘\",\n",
       " '인간의 분류학적 분류를 식별합니다.',\n",
       " '다음 숫자로 수학 문제를 구성합니다.',\n",
       " '신용 데이터로 로지스틱 회귀 모델을 훈련합니다.',\n",
       " '관용구를 문자 그대로의 의미로 바꾸어 문장을 다시 작성합니다.',\n",
       " '다음 직무에 대한 이력서를 작성하세요.',\n",
       " '고객 서비스에 대한 트윗을 작성합니다.',\n",
       " '신진대사의 과학적 정의는 무엇인가요?',\n",
       " 'Wildcard 인증서를 생성해줘. 도메인 이름은 *.example.org이며, email 검증을 사용해서 도메인 소유권을 인증해줘.',\n",
       " '주어진 정의가 왜 틀렸는지 설명하세요.',\n",
       " '주어진 구절을 과거형으로 다시 씁니다.',\n",
       " \"Delivery Stream의 이름을 'tester-partitioning-delimiter'로 설정하고, Amazon S3로 데이터를 전송하는 Delivery Stream을 만드는 템플릿을 작성해줘.\",\n",
       " '좋아하는 국가의 여행 목적지 예시를 생성합니다.',\n",
       " '이 문서에 관련된 중요한 사람들의 목록을 생성합니다.',\n",
       " '새로운 Kinesis 스트림을 만드는데, 샤드 수는 5로 설정하고, 데이터 보존 기간은 기본값을 사용해줘.',\n",
       " '주어진 주제에 대해 짧은 단락을 작성합니다.',\n",
       " '자연어 처리의 개념을 설명합니다.',\n",
       " '성공적인 관리자가 되기 위해 필요한 것이 무엇인지 설명하세요.',\n",
       " 'signed URLs와 signed cookies에 사용할 공개 키를 포함해줘',\n",
       " '주어진 문제를 해결하기 위해 적절하고 서로 다른 두 가지 방법을 제안하십시오.',\n",
       " '다음 회사에 적합한 슬로건을 생성하세요.',\n",
       " 'GPT 언어 모델의 개념을 설명합니다.',\n",
       " \"사용자 클레임 'role'을 주요 태그 'user_role'에 매핑하는 IdentityPoolPrincipalTag 구성을 생성해줘. IdentityPoolId를 'us-east-1:example-pool', 그리고 IdentityProviderName을 'example.idp.com'으로 설정해줘.\",\n",
       " \"VPC 구성이 있는 S3 액세스 포인트를 생성하는 CloudFormation 템플릿을 작성해줘. 버킷은 'my-restricted-bucket', VPC ID는 'vpc-1234567890abcdef0'로 설정해줘\",\n",
       " '\"실로폰\"이라는 단어의 철자를 입력합니다.',\n",
       " '이 문장을 미래형으로 변경합니다.',\n",
       " '생성할 자동 스케일링 그룹 이름을 myAutoScalingGroup으로 설정하고, 생명주기 전환 이벤트를 EC2 인스턴스 종료 시로 설정해 주며, 대기 시간을 300초로 설정하는 생명주기 후크 CloudFormation 템플릿을 만들어줘.',\n",
       " '다중-리전 키를 삭제할 때 대기 기간을 10일로 설정하는 AWS KMS 복제키 생성에 대한 CloudFormation 템플릿을 만들어주세요.',\n",
       " 'Lambda 함수를 사용하여 Auto Scaling 그룹을 생성하고 그 Auto Scaling 그룹의 ARN을 사용하여 Auto Scaling 그룹 capacity provider, 클러스터, 그리고 그 사이의 capacity provider association을 설정해줘.',\n",
       " \"Redshift ScheduledAction 리소스 생성시, EndTime을 '2023-12-31T23:59:59'로, ScheduledActionDescription을 'My scheduled resize action'로 설정해줘\",\n",
       " '이 회사에서 일하고 싶은 이유를 설명하세요.',\n",
       " '재치 있고 기사를 요약하는 새 헤드라인을 작성합니다.',\n",
       " \"CloudFormation을 사용하여 S3 StorageLens 구성을 생성하는 데, CSV 형식의 메트릭스 내보내기를 하도록 설정해줘. 대상 버킷은 'destination_metrics_bucket'로 사용해줘.\",\n",
       " '기존에 훈련된 모델을 사용하여 새로운 SageMaker 엔드포인트를 생성하는 프로세스를 CloudFormation을 이용하여 자동화하는 템플릿을 만들어줘',\n",
       " '물과 기름을 비교하고 대조하세요.',\n",
       " '기술 전문가가 아닌 청중에게 버블 정렬 알고리즘의 개념을 설명합니다.',\n",
       " '화씨에서 섭씨로 온도를 변환합니다.',\n",
       " '스컹크 양배추는 어떤 종류의 식물인가요?',\n",
       " '이 과제에서는 \"잠시 쉬다\"라는 문구에 대한 적절한 답변을 작성해야 합니다.',\n",
       " '솅겐 지역에 있는 국가를 나열합니다.',\n",
       " '다음 정치 성명을 분석하고 그 정확성을 판단하세요.',\n",
       " '이 과제에서는 아래 선택 사항에서 문장의 출처를 식별해야 합니다.\\n\\n출력은 다음 중에서 선택해야 합니다:\\n- 신문\\n- 교과서\\n- 온라인 기사\\n- 백과사전',\n",
       " '중국에서 가장 인구가 많은 6개 도시의 이름을 말하세요.',\n",
       " '이 속담을 완성할 문구를 입력하세요: \"____ 보다는 안전한 것이 낫다.\"',\n",
       " '주어진 구절을 요약합니다.',\n",
       " \"Oracle Engine을 사용한 Option Group을 만들어줘, EngineName을 oracle-ee로, MajorEngineVersion을 12.1로 설정해주고, OptionGroupDescription을 'A test option group'으로 설정해. 그리고 OptionConfigurations에 OEM과 APEX 옵션을 포함시켜줘. OEM 옵션에는 default라는 DBSecurityGroupMemberships과 Port 5500을 포함시켜줘.\",\n",
       " 'Identity Pool 이름을 MyAppIdentityPool로, OpenID Connect 제공자 ARN들을 포함하여 생성해줘',\n",
       " 'Route53Resolver용 FirewallDomainList 객체를 만들어줘. 도메인 파일 URL을 http://example.com/domains.txt로 설정하고, 이름을 MyFirewallDomainList로 설정해줘.',\n",
       " '이 1000단어짜리 글에서 해당되지 않는 단락을 삭제합니다.',\n",
       " '각 문장에서 홀수 단어를 골라보세요:',\n",
       " 'Lambda 함수를 특정 AWS 계정이나 서비스가 사용하도록 허용하는 템플릿을 만들어줘',\n",
       " \"HTTP API에 대한 Lambda Authorizer를 생성하되, Authorizer의 이름을 'MyCustomAuth', Authorizer 타입을 'REQUEST'로 설정하고, 인증서 ARN을 'arn:aws:iam::123456789012:role/apigatewayLambda'로 설정해줘\",\n",
       " '다음 문장을 과거형으로 고쳐 쓰세요.',\n",
       " 'cache.m3.medium 노드 타입을 사용하고 redis 2.8.6 엔진 버전으로 ElastiCache 복제 그룹을 생성해줘.',\n",
       " 'IBM의 CEO 알아보기',\n",
       " '스포츠에서 애널리틱스를 어떻게 활용할 수 있나요?',\n",
       " '멘토를 통해 얻을 수 있는 이점에 대해 설명하세요.',\n",
       " '사막 생물 군계의 두 가지 유형을 말하십시오.',\n",
       " '아래 기사를 5문장으로 요약하세요.',\n",
       " \"'My-Sample-Hook'의 ARN을 사용하여 CloudFormation에서 새로운 후크 구성을 설정해줘.\",\n",
       " '다음 목록을 알파벳 순으로 뒤집습니다.',\n",
       " 'ElastiCache 글로벌 복제 그룹을 생성하는 템플릿을 만들어줘. 자동 장애 조치 기능을 활성화하고, 캐시 노드 유형을 cache.t2.micro로 설정해줘.',\n",
       " '2층 주택의 배관 다이어그램 만들기',\n",
       " '간단한 언어를 사용하여 선형 회귀 모델의 개념을 설명합니다.',\n",
       " '2x^2 + 5x의 도함수를 계산합니다.',\n",
       " \"LocalGatewayRouteTableId가 'lgw-rtb-1234567890abcdef0', Tags가 [{'Key': 'Name', 'Value': 'MyAssociation'}], 그리고 VpcId가 'vpc-1234567890abcdef0'로 설정된 Local Gateway Route Table VPC Association을 만들어줘\",\n",
       " '4개의 소셜 미디어 플랫폼의 이름을 나열합니다.',\n",
       " 'SageMaker 모델을 배포하기 위해 엔드포인트 구성을 생성하고 연관된 엔드포인트를 생성하는 CloudFormation 템플릿을 제작해줘',\n",
       " '새롭게 생성되는 인스턴스를 위한 사용자 데이터 스크립트 실행 시간을 고려하여 인스턴스를 대기 상태로 유지하는 EC2 인스턴스 시작 시의 자동 스케일링 생명주기 후크와 함께 Auto Scaling 그룹을 만드는 CloudFormation 템플릿을 제공해줘.',\n",
       " 'DynamoDB 글로벌 테이블을 생성하되, 3개의 리전(us-east-1, eu-west-1, ap-northeast-2)에 복제본을 포함시켜, 스트림 활성화해줘',\n",
       " \"example.com 도메인을 위한 private hosted zone을 생성하는 CloudFormation 템플릿으로 만들어줘, 이때 VPC를 'vpc-abcd1234'(ap-northeast-1)와 'vpc-efgh5678'(us-west-2)에 연결해줘.\",\n",
       " '도서 추천 시스템을 위한 앱 인터페이스를 디자인합니다.',\n",
       " '다음 품목을 고체 또는 액체로 분류합니다.',\n",
       " '100단어 이하의 짧은 이야기를 작성하세요.',\n",
       " '좀 더 설명적인 단어로 문장을 다시 작성합니다.',\n",
       " '코로나 바이러스가 경제에 미치는 영향을 설명하세요.',\n",
       " '다음 객체를 사용하는 은유의 예를 들어 보세요.',\n",
       " '문장을 다시 작성하여 명확성과 흐름을 더 명확하게 합니다.',\n",
       " \"LogGroupArn을 'arn:aws:logs:us-east-1:123456789012:log-group:my-log-group:*'로 설정하고, hypervisor의 사용자 이름과 비밀번호를 각각 'admin', 'password123'으로 설정해서 BackupGateway Hypervisor 리소스를 만들어줘\",\n",
       " \"사용자 지정 플랫폼을 사용하는 Elastic Beanstalk 환경을 생성하는 템플릿을 만들어줘. 애플리케이션 이름을 'CustomPlatformApp'으로, 플랫폼 ARN을 'arn:aws:elasticbeanstalk:us-east-1::platform/CustomPlatformName/1.0.0'로 설정해줘.\",\n",
       " 'CloudFront에 새로운 origin request policy 추가해줘',\n",
       " '고양이와 개의 유사점과 차이점을 설명하세요.',\n",
       " \"'물건을 만드는 기술'이라는 문구에 대한 올바른 용어를 선택하세요.\",\n",
       " '이 문장에서 틀린 단어를 찾아보세요.',\n",
       " '주어진 작업 설명에 어떤 유형의 머신 러닝 기법이 적용될 수 있는지 파악합니다.',\n",
       " \"Git 설정을 포함하여 SageMaker 코드 저장소 생성하고, 저장소 URL을 'https://git.example.com/repository.git'로, Secrets Manager secret의 ARN을 'arn:aws:secretsmanager:us-west-2:123456789012:secret:gitCreds'로 설정해줘\",\n",
       " '다음 사람을 설명하세요.',\n",
       " '다음 텍스트를 읽기 쉽게 편집합니다.',\n",
       " '주어진 주제의 현재 상태에 대해 몇 문장을 작성하세요.',\n",
       " \"특정 태그로 모든 백업을 분류하는 백업 계획을 설정하는 템플릿을 생성해줘, 태그는 {'Department':'Finance'}로 설정해줘\",\n",
       " '다음 코드 스니펫을 리버스 엔지니어링하고 무슨 일이 일어나고 있는지 4문장으로 설명하세요.\\n\\nvar x = 3\\nvar y = x + 4',\n",
       " '수분을 유지하는 것이 중요한 이유를 설명하세요.',\n",
       " '단어를 재배열하여 완전한 문장을 만듭니다.',\n",
       " \"S3 on Outposts 버킷 생성을 위한 CloudFormation 템플릿을 만들어 줘. 버킷은 'DOC-EXAMPLE-BUCKET'로 이름 지정되어야 하고, OutpostID는 'op-01ac5d28a6a232904'로 설정해줘.\",\n",
       " '다음 인시던트를 프로토콜 위반으로 분류하세요. 위반이 있으면 1을 출력하고 위반이 없으면 0을 출력합니다.',\n",
       " '내일 로스앤젤레스의 날씨를 예측하세요.',\n",
       " \"EFS One Zone 파일 시스템을 사용해서 종류별 'us-east-1a' 가용 영역에 파일 시스템을 생성하는 템플릿을 만들어줘.\",\n",
       " \"Route 53 Resolver를 AWS Outpost에서 구동하도록 설정해줘. 이때, 이름을 'OutpostDNSResolver', PreferredInstanceType을 't3.medium'으로, 및 여러 태그들이 포함된 CloudFormation 템플릿 만들어줘.\",\n",
       " '애플리케이션 이름이 AnalyticsApp이고, 외부 대상으로 Amazon Kinesis Firehose delivery stream을 사용하는 ApplicationOutput 리소스를 추가하는 템플릿을 만들어줘.',\n",
       " \"SageMaker 코드 저장소를 생성하되, 이름을 'projectRepo', 저장소 URL을 'https://git.example.com/projectRepo.git'로 설정하고, 저장소 접속을 위한 Secrets Manager secret의 ARN을 'arn:aws:secretsmanager:us-east-1:123456789012:secret:projectGitCreds'로 설정해줘\",\n",
       " 'AccessPolicy로 S3 버킷 접근을 제한하고, Notifications로 SNS 주제 arn:aws:sns:us-east-1:123456789012:MyBackupVaultNotifications를 사용하는 BackupVault를 구성해줘',\n",
       " \"SageMaker 추론 실험 설정을 위한 템플릿을 만들어줘. 엔드포인트 이름을 'InferenceEndpoint'로, 실험 이름을 'MyInferenceExperiment'로 설정해줘.\",\n",
       " '가정에서 전기 사용량을 줄이기 위한 계획을 수립하세요.',\n",
       " '식료품점에서 구입할 수 있는 5가지 품목 나열하기',\n",
       " \"PubliclyAccessible을 false로 설정하고, SecurityGroupIds를 ['sg-12345', 'sg-67890']로 설정하며, SubnetIds를 ['subnet-12345', 'subnet-67890']로 설정하는 Redshift Serverless Workgroup CloudFormation 템플릿 생성해줘.\",\n",
       " '신발 회사를 위한 로고를 만듭니다.',\n",
       " 'ContinuousDeploymentPolicyConfig 속성을 가지고 있는 CloudFront의 ContinuousDeploymentPolicy를 생성해줘.',\n",
       " '백업 계획 리소스를 사용해 일일 백업 설정을 포함하는 CloudFormation 템플릿 생성해줘',\n",
       " '다른 시제로 문장을 다시 작성합니다.',\n",
       " '글로벌 온라인 금융 시스템에 대한 잠재적인 보안 위협을 식별합니다.',\n",
       " \"AWS 리전 us-west-2에 위치한 주요 키를 복제하는 복제키를 생성하는, 설명이 '테스트 복제키'인 CloudFormation 템플릿을 만들어줘.\",\n",
       " '다음 그림의 표면적을 결정합니다.',\n",
       " '시험을 성공적으로 완료하기 위한 커트라인 점수 찾기',\n",
       " '정수 배열이 주어지면 첫 번째로 반복되는 요소를 반환합니다.',\n",
       " '특정 VPC(vpc-789ghijk)에 대한 EgressOnlyInternetGateway 리소스를 포함하는 CloudFormation 템플릿을 만들어줘',\n",
       " '\"Customers\"라는 테이블에서 처음 5개의 레코드를 검색하는 SQL 쿼리를 작성합니다.',\n",
       " 'Server 컴퓨팅 플랫폼을 사용하는 CodeDeploy 애플리케이션 생성해줘.',\n",
       " '게티스버그 전투의 중요성을 설명하세요.',\n",
       " '새 앱을 출시하기 위한 두 가지 마케팅 전략을 제안하세요.',\n",
       " '다음 입력을 기반으로 질문을 생성합니다.',\n",
       " '다음 문장을 수정하여 명확성과 흐름을 개선합니다.',\n",
       " 'Tags과 NetworkInsightsPathId 속성을 가진 NetworkInsightsAnalysis 인스턴스를 생성해줘.',\n",
       " \"가용 영역 'us-east-1b'에 위치한 EFS 파일 시스템의 태그를 'Name: ProductionData'로 설정하고 자동 백업을 사용 설정하는 템플릿을 만들어줘.\",\n",
       " '스테이크를 요리하는 독특한 방법을 설명하세요.',\n",
       " \"최소 한 개의 컨트롤로 구성된 프레임워크를 생성하고, 프레임워크의 이름을 'ComplianceFramework2023'로 설정해줘\",\n",
       " '이진 트리에서 두 노드의 첫 번째 공통 조상을 찾는 알고리즘을 생성합니다.',\n",
       " '삼림 벌채의 결과를 간략하게 설명합니다.',\n",
       " \"IPAMAllocation에 대한 CIDR 할당을 설명하는 문자열과 함께 IPAMPoolId를 'pool-12345'로 설정해줘\",\n",
       " '찰스 2세 왕의 생애와 통치에 대해 설명하세요.',\n",
       " '문자열 목록을 알파벳순으로 정렬하는 함수 생성하기',\n",
       " 'Cognito 사용자 풀의 내장 앱 UI에 대한 UI 커스터마이징 정보를 설정하되, 특정 clientId를 가진 단일 클라이언트에 대해 설정해줘',\n",
       " '곱셈을 위한 연습 문제 3개 제공',\n",
       " '인구가 급격히 증가하는 도시를 위한 교통 솔루션을 제안하세요.',\n",
       " \"Redshift Serverless 네임스페이스 생성을 위한 템플릿을 만들어줘. 관리자의 사용자 이름을 'admin', 비밀번호를 'password123', 데이터베이스 이름을 'mydatabase', 네임스페이스 이름을 'mynamespace' 로 설정해줘.\",\n",
       " '주말에 친구들과 함께 할 수 있는 재미있는 활동 4가지를 제안하세요.',\n",
       " '개인 성과와 사회적 성과의 효과 비교 및 대조',\n",
       " '새로운 Hook버전을 지정하고 Ref리턴 값으로 해당 버전을 기본 버전으로 설정하는 CloudFormation 템플릿을 생성해줘',\n",
       " '플라스틱 쓰레기를 줄일 수 있는 3가지 잠재적 해결책을 제시하세요.',\n",
       " '재생 가능 에너지원을 지지하는 논거를 종합합니다.',\n",
       " '문장의 단어를 재배열하여 질문을 만듭니다.',\n",
       " '문장이 주어지면 이를 수동태로 변환합니다.',\n",
       " '마크 트웨인이 가장 최근에 쓴 책 다섯 권을 나열하세요.',\n",
       " '3원색이란 무엇인가요?',\n",
       " '5가지 과일 나열',\n",
       " 'HTML(하이퍼텍스트 마크업 언어)의 용도를 설명합니다.',\n",
       " '다음 단어를 배열하여 의미 있는 문장을 만드세요: 판매하다 투자자에게 조언하다 신뢰하다.',\n",
       " '소셜 미디어 캠페인 슬로건을 생각해 보세요.',\n",
       " '유명한 과학자에 대해 조사하고 그에 대한 간단한 약력을 제공하세요.',\n",
       " \"CloudFormation에서 실행 역할 ARN이 'arn:aws:iam::123456789012:role/CfnRole'인 리소스 버전을 하나 생성해줘. 이 리소스의 타입 이름은 'My::Sample::Resource', SchemaHandlerPackage는 's3://my-sample-resourceversion-bucket/my-resource.zip'으로 설정해줘.\",\n",
       " '매일 오후 7시에 최소 1개의 EC2 인스턴스를 가지며 최대 크기가 10인 Auto Scaling 그룹을 조정하는 예정된 작업을 설정하는 CloudFormation 템플릿을 생성해줘.',\n",
       " \"Queue URL이 'https://sqs.us-east-1.amazonaws.com/123456789012/my-queue'로, 정책 문서가 주어진 SQS 큐 인라인 정책 생성해줘\",\n",
       " \"Lightsail 서비스의 TLS/SSL 인증서를 생성하는데 필요한 정보를 입력해줘. 인증서 이름을 'MyWebsiteCert', 도메인 이름을 'example.com'으로 설정하고, 대체 이름을 'www.example.com'과 'mail.example.com'으로 설정해줘.\",\n",
       " '\"그들은\"의 축약은 무엇인가요?',\n",
       " '다음 시를 분석합니다.',\n",
       " '건강하게 먹고 싶지만 예산이 한정된 사람을 위해 내일의 식사 계획을 준비하세요.',\n",
       " '주어진 사다리꼴의 넓이를 구합니다.',\n",
       " \"태그와 생명 주기 설정이 있는 S3 on Outposts 버킷을 생성하는 CloudFormation 템플릿을 만들어줘. 버킷 이름은 'DOC-EXAMPLE-BUCKET', OutpostID는 'op-01ac5d28a6a232904'. 태그는 'stage'가 'beta', 'purpose'가 'testing'으로, 4개의 생명 주기 규칙을 설정해줘. 첫번째 규칙은 2일 후에 객체를 만료시키고, 두번째 규칙은 미완성 멀티파트 업로드를 2일 후에 중단시켜줘.\",\n",
       " '주어진 문장을 명령문으로 변환합니다.',\n",
       " '신진대사를 개선하기 위한 팁 목록을 생성합니다.',\n",
       " \"SageMaker 코드 저장소를 만드는데, 저장소 이름을 'myCodeRepo'로 설정해줘\",\n",
       " 'SNS 주제 정책과 연결된 CloudFormation 템플릿을 생성해줘. 정책 문서는 주어진 입력을 그대로 사용하고, 주제는 단일 ARN으로 설정해줘.',\n",
       " 'EFS 파일 시스템 fs-09abcdef012345678와 연동된 마운트 타겟을 생성하는데, 서브넷은 subnet-abcdef0123456789를 사용하고, 보안 그룹을 아무 가지 않도록 설정해줘.',\n",
       " '해변의 일몰에 대한 창의적인 설명을 생성하세요.',\n",
       " 'VPN 연결의 정적 루트를 추가해줘. 목적지 CIDR 블록은 192.168.1.0/24이고, VPN 연결 ID는 MyVpnConnection이야',\n",
       " 'Cognito User Pool Client 생성하되, 리프레시 토큰 유효 기간을 30일로 설정해줘.',\n",
       " '문장을 완성하는 올바른 단어를 식별합니다.',\n",
       " '요한과 마리아의 관계를 분류합니다.',\n",
       " '문장에서 어떤 단어가 가장 비중이 높은지 알아보세요.',\n",
       " '컴퓨터 시스템의 구성 요소 두 가지를 말하십시오.',\n",
       " 'ECR 레지스트리의 내용을 us-east-2 및 us-west-1 리전으로 복제하기 위한 템플릿을 만들어줘',\n",
       " '아래에 주어진 구절에 대한 요약을 제공하세요.',\n",
       " '지속 가능한 에너지의 중요성을 설명하는 200단어 에세이를 작성하세요.',\n",
       " 'TagFilters를 기반으로 ApplicationSource를 설정하고, ASGAverageCPUUtilization을 이용한 타겟 트래킹 설정을 포함한 Auto Scaling Scaling Plan을 CloudFormation으로 구성해줘.',\n",
       " '고정된 메세지로 특정 SNS 토픽에 알림을 보내는 CloudWatch 복합 알람을 만들어줘. 복합 알람의 이름은 DeploymentInProgress로 설정해줘.',\n",
       " 'Outpost에서 S3 버킷을 생성하고 버킷 정책을 추가해주는 템플릿 생성해줘',\n",
       " '제공된 출처 설정을 사용하여 Elastic Beanstalk configuration template을 만들어줘. 애플리케이션 이름을 SourceApp이고 출처 템플릿 이름을 BaseTemplate로 설정해줘.',\n",
       " '소셜 미디어에서 가장 많이 공유되는 콘텐츠 유형은 무엇인가요?',\n",
       " '3인칭 시점을 사용하여 이 문장을 다시 작성합니다.',\n",
       " '스트레스를 줄이는 데 도움이 되는 팁 목록을 작성하세요.',\n",
       " '다음 문장을 참 또는 거짓으로 분류하세요.',\n",
       " '다음 뉴스 기사를 140자 이내로 요약한 트윗을 작성합니다.',\n",
       " '주어진 역사적 인물에 대해 몇 문장을 써보세요.',\n",
       " '이 수학 문제에 답하세요.',\n",
       " '3일간의 여행 일정의 개요를 작성하세요.',\n",
       " '다음 주제에 대한 트윗을 작성합니다.',\n",
       " '잘못된 단어를 식별하고 더 나은 버전을 제안하세요.',\n",
       " 'Kinesis Video Streams에 새로운 스트림을 만들고 데이터 보존 시간을 24시간으로 설정해줘',\n",
       " \"CloudFormation 템플릿을 사용하여 'My::Sample::Hook'의 이름으로 새로운 후크 구성을 지정해줘.\",\n",
       " \"보안 그룹 설명을 'Public Redshift Access'로 한 Amazon Redshift 보안 그룹에 대한 CloudFormation 템플릿을 생성해줘\",\n",
       " \"SageMaker의 JupyterServer 유형 앱을 생성하되, 앱 이름을 'AnalysisApp', 도메인 ID를 'd-0987654321'로 설정하고 태그에 {'Project':'DataAnalysis', 'Owner':'AnalystTeam'}를 추가해줘.\",\n",
       " '두 종교, 기독교와 이슬람교를 비교하고 대조해 보세요.',\n",
       " '셀의 부분을 식별하고 정의합니다.',\n",
       " 'Kinesis Analytics V2에서 애플리케이션 이름을 SampleApp으로 하고, CloudWatch 로그 스트림 ARN을 arn:aws:logs:eu-central-1:987654321098:log-group:ExampleLogGroup:log-stream:ExampleLogStream으로 설정하는 로깅 옵션을 추가해줘',\n",
       " '여우원숭이에 관한 운문시를 생성합니다.',\n",
       " 'AMI ID가 ami-0a123b456c789d012이고 인스턴스 타입이 t3.large인 EC2 인스턴스용 템플릿을 생성해줘',\n",
       " \"integration 및 route 설정을 변경하되, API 'api-abcde'를 위한 설정만 포함시켜줘\",\n",
       " '이 블로그 게시물을 평가합니다. \"좋음\" 또는 \"나쁨\"을 출력합니다.',\n",
       " 'DynamoDB 테이블에 글로벌 보조 인덱스와 로컬 보조 인덱스를 추가하는 템플릿을 만들어줘',\n",
       " '두 숫자 사이의 기하 평균을 구하는 수학 방정식을 작성하세요.',\n",
       " '기쁨을 표현하는 시를 만들어 보세요.',\n",
       " \"CloudFormation 템플릿으로 프로젝트 이름이 'VehicleDetectionProject'인 Rekognition 프로젝트 만들기\",\n",
       " \"DeploymentConfigName을 'MyServerDeploymentConfig'로 설정하고, 서버 기반 배포에 최소 2대의 인스턴스가 항상 건강해야 하는 CodeDeploy DeploymentConfig 리소스를 생성하라.\",\n",
       " '다음 문장을 올바른 문법이 되도록 수정합니다.',\n",
       " \"Redshift EndpointAccess 리소스를 생성하는 템플릿을 만들어줘. 클러스터 식별자를 'my-redshift-cluster', 엔드포인트 이름을 'my-endpoint', 서브넷 그룹 이름을 'my-subnet-group', 그리고 보안 그룹 ID 리스트를 ['sg-12345', 'sg-67890']로 설정해줘\",\n",
       " '영화에 등장하는 주인공 다섯 명을 나열합니다.',\n",
       " \"모델 패키지 그룹 이름이 'NewModelGroup'인 SageMaker 리소스를 만들어줘\",\n",
       " '데모 결과를 바탕으로 프로그램 실행을 개선할 수 있는 방법을 제안하세요.',\n",
       " '변의 길이가 8cm, 5cm, 6cm인 삼각형의 넓이를 계산합니다.',\n",
       " \"DB 서브넷 그룹 이름을 'TestDBSubnet'으로 설정하고 서브넷 ID 'subnet-90ab12cd', 'subnet-78ef34gh'를 포함하는 RDS DB 서브넷 그룹 생성 템플릿을 만들어 줘\",\n",
       " '성공적인 치과 마케팅 캠페인을 만드세요.',\n",
       " 'CarrierGateway 리소스 구성을 위해 태그를 할당하고 VPC ID를 vpc-1234567890abcdef0로 지정한 템플릿을 생성해줘',\n",
       " 'CloudFront 배포를 위한 모니터링 구독 설정을 포함하는 템플릿 생성하기',\n",
       " \"100GB 용량의 Lightsail 디스크를 us-east-1a 가용 지역에 생성하는 CloudFormation 템플릿을 작성해줘. 디스크 이름은 'DataDisk'로 설정해줘.\",\n",
       " '긍정적인 태도 5가지 목록을 생성합니다.',\n",
       " \"DB 인스턴스 식별자가 'DBInstanceID1'이고 대상 그룹 이름이 'default'인 RDS DBProxyTargetGroup 리소스를 생성하는 템플릿 만들어줘\",\n",
       " '블록체인의 개념을 설명합니다.',\n",
       " '한 변의 길이가 5cm인 정사각형의 넓이를 구합니다.',\n",
       " '르네상스 시대를 설명합니다.',\n",
       " '종이로 할 수 있는 일을 말해보세요.',\n",
       " \"Local Gateway Route Table VPC Association을 생성해줘. 이때 LocalGatewayRouteTableId를 'lgw-rtb-abcdef1234567890'으로, 그리고 VpcId를 'vpc-abcdef1234567890'로 설정해줘\",\n",
       " '서반구의 국가 이름 목록을 생성합니다.',\n",
       " '이 신제품의 이름을 생각해 보세요.',\n",
       " '환경 파괴 문제를 다루는 트윗을 작성합니다.',\n",
       " 'Auto Scaling 그룹 capacity provider와 두 개의 Auto Scaling 그룹 capacity provider를 사용하여 클러스터 capacity provider association을 생성해줘.',\n",
       " \"VPC 링크를 생성하는데, 이름을 GatewayVpcLink로 설정하고, 'subnet-012abcde', 'subnet-334defgh'의 서브넷 ID와 ['sg-001abc', 'sg-002def']의 보안 그룹 ID를 설정해줘. 또한 태그로 {'Project':'MyApiProject'}를 추가해줘.\",\n",
       " '주어진 항목을 가족에 따라 분류합니다.',\n",
       " '고객 참여를 높일 수 있는 비즈니스용 웹 페이지를 개발하세요.',\n",
       " '새로운 Hook 버전을 지정하는 CloudFormation 템플릿을 만들어줘',\n",
       " 'Lambda 레이어를 생성하고, 여기에 호환가능한 아키텍처 2개를 명시해줘',\n",
       " 'HTML과 CSS의 차이점을 설명합니다.',\n",
       " '\"영향\"이라는 단어의 동의어를 사용하여 다음 문장을 다시 작성합니다: 팬데믹의 영향은 엄청난 것이었다.',\n",
       " '문서에 다음 텍스트를 추가합니다.',\n",
       " '교실에서 기술을 사용하는 창의적인 방법 5가지 목록을 생성합니다.',\n",
       " 'example.com 도메인을 위한 public hosted zone 생성하는 템플릿을 만들어줘.',\n",
       " \"example.com에 대해 DNS query logging을 활성화하고, 로그 그룹으로 'arn:aws:logs:us-east-1:123412341234:log-group:/aws/route53/*'을 사용하는 public hosted zone을 구성해줘.\",\n",
       " '다음 문장을 수정하여 문법 오류를 제거합니다: 그들은 하루 종일 차를 고치려고 노력했습니다.',\n",
       " '머신러닝과 딥러닝의 차이점은 무엇인가요?',\n",
       " 'CloudWatch 복합 알람 생성을 위한 템플릿을 만들어줘. 알람 이름을 HighResourceUsage로 설정하고, 알람 규칙으로는 HighCPUUsage와 HighMemoryUsage 두 알람이 모두 ALARM 상태일 때, 그리고 DeploymentInProgress 알람이 ALARM 상태가 아닐 때 ALARM 상태로 전환되도록 해줘.',\n",
       " '서로 다른 배경을 가진 두 소년의 우정에 관한 이야기를 써보세요.',\n",
       " '보육 센터의 로고를 디자인하세요.',\n",
       " '이 텍스트의 주요 아이디어는 무엇인가요?',\n",
       " \"hosted zone 'Z1D633PJN98FT9'에 대한 Route53 RecordSetGroup을 생성하되, Comment는 지정하지 말고, HostedZoneId만 활용해서 지정해줘.\",\n",
       " \"키 ID가 '123apiKey'이고 사용 계획 ID가 'plan123'인 ApiGateway 사용 계획 키를 만들어줘\",\n",
       " '이 의견이 잘못된 이유를 설명하세요.',\n",
       " \"Lambda 함수의 특정 버전에 별칭을 만들고, 이 별칭에 대한 설명과 함수 이름, 함수 버전을 제공하려고 해. 별칭의 이름을 'ProductionAlias', 설명을 'Production version of the function', 함수 버전을 '1'로 설정해줘\",\n",
       " '다음 문장을 단수형에서 복수형으로 변경합니다.',\n",
       " \"SageMaker ModelPackage 리소스 생성을 위한 CloudFormation 템플릿을 만들어줘. 모델 패키지 상태 상세 정보에서 생성 상태를 'COMPLETED'로 설정하고, 태그를 키-값 쌍으로 'department':'AI'와 'project':'QuickStart'로 설정해줘\",\n",
       " '다음 문장을 수정하여 더 간결하게 만듭니다.',\n",
       " \"S3 버킷에 대한 액세스 포인트를 생성하고, 버킷 이름을 'my-bucket'으로 설정한 CloudFormation 템플릿을 만들어줘\",\n",
       " 'Kinesis Analytics 애플리케이션에서 Amazon S3의 객체 데이터를 사용해 내부 애플리케이션 테이블을 생성하는 템플릿을 만들어줘',\n",
       " 'VPC 보안 그룹 ID를 sg-04acd7567bEXAMPLE와 sg-0a123456789EXAMPLE로 설정하고, 엔진 패밀리를 POSTGRESQL로 설정하는 RDS DB 프록시용 CloudFormation 템플릿 만들어줘',\n",
       " '교육에서 기술이 어떻게 사용되는지 예를 들어 보세요.',\n",
       " '소설 스토리를 위한 아이디어를 생성하세요.',\n",
       " '논리적 오류를 피하기 위해 다음 문장을 다시 작성하세요.',\n",
       " '스토리의 새로운 결말을 생성하세요.',\n",
       " 'AWSSDK/Java 네임스페이스에서 JvmMetric 메트릭에 대한 UsedMemory 차원의 평균에 대한 이상 감지 설정을 구성해라.',\n",
       " '같은 아이디어를 더 설득력 있게 표현하려면 이 문장을 다시 작성하세요.\\n출력은 한 문장으로 작성해야 합니다.',\n",
       " '전통 중국 요리를 제공하는 레스토랑의 로고를 디자인하세요.',\n",
       " '주어진 목록을 정렬하는 알고리즘을 설계합니다.',\n",
       " '복제 설정을 사용하여 ECR private 레지스트리를 업데이트하는 템플릿을 만들어줘',\n",
       " '제품의 소셜 미디어 계정에서 참여도를 높일 수 있는 3가지 마케팅 아이디어를 생성하세요.',\n",
       " '건강을 유지하기 위한 세 가지 팁을 알려주세요.',\n",
       " '다른 AWS 계정에 있는 VPC와 VPC 피어링 연결을 설정해줘. 피어링할 VPC의 ID는 \"vpc-1234abcd\"고, 피어 영역은 \"us-west-2\"야. 태그는 이름을 \"VPC Peering Example\"로 설정해줘.',\n",
       " '로스앤젤레스에서 필라델피아로 비행하는 두 사람의 총 여행 비용을 계산합니다.',\n",
       " \"public 도메인 이름을 'example.com'으로 설정한 Lightsail 컨테이너 서비스를 만드는 템플릿을 작성해줘. 파워는 'small'로, 스케일은 5로 설정해줘.\",\n",
       " '스포츠 이벤트를 설명하는 단락을 작성하세요.',\n",
       " '섭씨에서 화씨로 변환합니다.',\n",
       " '다음 텍스트를 긍정 또는 부정의 두 가지 감정 표현 클래스 중 하나로 분류합니다.',\n",
       " '소프트웨어 개발 수명 주기의 여러 단계에 대해 설명합니다.',\n",
       " \"'enable_user_activity_logging' 파라미터를 'false'로 변경하고 파라미터 그룹 설명을 'Updated parameter group'로 설정하여 Redshift ClusterParameterGroup 템플릿을 만들어줘.\",\n",
       " 'Viewer access를 CloudFront를 통해서만 가능하게 하는 Origin Access Control 설정으로 CloudFront distribution에 추가해줘.',\n",
       " '다음 문장을 편집하여 모든 수동태를 제거합니다.',\n",
       " \"고객 게이트웨이를 생성하되, BGP ASN을 65534, IP 주소를 '12.1.2.3'로 설정해줘\",\n",
       " '이름이 \"T\"로 시작하는 쥬라기 시대의 공룡 종을 찾습니다.',\n",
       " \"SageMaker 작업 팀 생성을 위한 CloudFormation 템플릿을 만들어줘. 이때 작업 팀 이름을 'AnnotationTeam', 태그를 {'Team':'Annotation', 'Department':'AI'}로 추가해주고, 설명을 'Team for image annotation tasks'로 설정해줘.\",\n",
       " 'ElastiCache Redis 사용자 그룹을 redis 엔진으로 생성하고, 태그로 Project:Experiment를 추가해줘. 사용자 그룹 ID는 experimentGroup으로, 사용자 ID 리스트에는 default만 포함해줘',\n",
       " '주어진 기사를 1~2문장으로 요약합니다.',\n",
       " '수렴하는 경계의 예를 들어 보겠습니다.',\n",
       " \"SageMaker 프로젝트에서 Service Catalog를 사용하여 제품을 프로비저닝하는 템플릿을 만들어줘. 프로덕트 ID는 'prod-abcd1234', 프로비저닝 아티팩트 ID는 'pa-abcd1234'를 사용해줘.\",\n",
       " '모든음절의 예를 만듭니다.',\n",
       " '두 가지 유형의 컴퓨터 네트워크를 비교하고 대조합니다.',\n",
       " 'AWS KMS 내에서 다중-리전 복제키와 주요 키 간의 동기화되지 않는 속성에는 무엇이 포함되나요?',\n",
       " '다른 사람을 팀에 초대하는 메시지를 작성합니다.',\n",
       " '지구 온난화의 결과에 대한 질문을 만듭니다.',\n",
       " '웹 개발 회사를 위한 로고를 디자인하세요.',\n",
       " '앵무새 죽이기 책에 대한 분석 생성하기']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 1330/1330 [00:00<00:00, 10779.17it/s]\n",
      "Tokenizing: 100%|██████████| 333/333 [00:00<00:00, 10460.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomDataset(\n",
    "    data=question_train,\n",
    "    target=target_train,\n",
    "    model_name=model_name,\n",
    "    text_columns=\"question\",\n",
    "    max_length=256,\n",
    "    state=\"train\",\n",
    ")\n",
    "\n",
    "val_data = CustomDataset(\n",
    "    data=question_valid,\n",
    "    target=target_valid,\n",
    "    model_name=model_name,\n",
    "    text_columns=\"question\",\n",
    "    max_length=256,\n",
    "    state=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangwon/.pyenv/versions/3.10.13/envs/cfn-llm/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "  0%|          | 0/210 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "  2%|▏         | 4/210 [00:24<13:38,  3.97s/it]  Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x10782fbe0>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x2ab0a1e00>\n",
      "        name = Apple M1 Pro \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x124f60000>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x2ab0a1e00>\n",
      "            name = Apple M1 Pro \n",
      "    retainedReferences = 1\n",
      " 10%|█         | 21/210 [01:07<24:45,  7.86s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "Downloading builder script: 100%|██████████| 6.77k/6.77k [00:00<00:00, 8.54MB/s]\n",
      "                                                \n",
      " 10%|█         | 21/210 [01:39<24:45,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6844255328178406, 'eval_f1': 0.7504690431519699, 'eval_runtime': 31.6654, 'eval_samples_per_second': 10.516, 'eval_steps_per_second': 0.189, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20%|██        | 42/210 [02:32<20:10,  7.20s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                \n",
      " 20%|██        | 42/210 [03:02<20:10,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6841882467269897, 'eval_f1': 0.7504690431519699, 'eval_runtime': 29.3795, 'eval_samples_per_second': 11.334, 'eval_steps_per_second': 0.204, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 24%|██▍       | 50/210 [03:19<06:36,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6614, 'grad_norm': 1.0868926048278809, 'learning_rate': 7.61904761904762e-06, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 63/210 [03:55<17:38,  7.20s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                \n",
      " 30%|███       | 63/210 [04:25<17:38,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6861188411712646, 'eval_f1': 0.9393939393939394, 'eval_runtime': 29.5784, 'eval_samples_per_second': 11.258, 'eval_steps_per_second': 0.203, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 40%|████      | 84/210 [05:18<15:06,  7.19s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                \n",
      " 40%|████      | 84/210 [05:49<15:06,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6874817609786987, 'eval_f1': 0.15668202764976957, 'eval_runtime': 30.604, 'eval_samples_per_second': 10.881, 'eval_steps_per_second': 0.196, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 48%|████▊     | 100/210 [06:16<02:21,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5543, 'grad_norm': 1.4174736738204956, 'learning_rate': 5.2380952380952384e-06, 'epoch': 4.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 105/210 [06:42<12:40,  7.24s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                 \n",
      " 50%|█████     | 105/210 [07:14<12:40,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.682039737701416, 'eval_f1': 0.2608695652173913, 'eval_runtime': 31.2133, 'eval_samples_per_second': 10.669, 'eval_steps_per_second': 0.192, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 60%|██████    | 126/210 [08:06<10:04,  7.19s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                 \n",
      " 60%|██████    | 126/210 [08:35<10:04,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5800318717956543, 'eval_f1': 0.8636363636363636, 'eval_runtime': 29.3466, 'eval_samples_per_second': 11.347, 'eval_steps_per_second': 0.204, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 70%|███████   | 147/210 [09:29<07:34,  7.22s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                 \n",
      " 70%|███████   | 147/210 [09:59<07:34,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5767043232917786, 'eval_f1': 0.8235294117647058, 'eval_runtime': 29.766, 'eval_samples_per_second': 11.187, 'eval_steps_per_second': 0.202, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 71%|███████▏  | 150/210 [10:11<08:51,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4746, 'grad_norm': 2.605710506439209, 'learning_rate': 2.8571428571428573e-06, 'epoch': 7.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 168/210 [10:52<05:01,  7.18s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                 \n",
      " 80%|████████  | 168/210 [11:22<05:01,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4978097081184387, 'eval_f1': 0.9159891598915989, 'eval_runtime': 29.603, 'eval_samples_per_second': 11.249, 'eval_steps_per_second': 0.203, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 90%|█████████ | 189/210 [12:15<02:31,  7.20s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                 \n",
      " 90%|█████████ | 189/210 [12:45<02:31,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4933280944824219, 'eval_f1': 0.9130434782608695, 'eval_runtime': 30.1528, 'eval_samples_per_second': 11.044, 'eval_steps_per_second': 0.199, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 95%|█████████▌| 200/210 [13:07<00:16,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4349, 'grad_norm': 1.2843250036239624, 'learning_rate': 4.7619047619047623e-07, 'epoch': 9.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [13:39<00:00,  7.20s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                 \n",
      "100%|██████████| 210/210 [14:08<00:00,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5021293759346008, 'eval_f1': 0.8980716253443526, 'eval_runtime': 29.4923, 'eval_samples_per_second': 11.291, 'eval_steps_per_second': 0.203, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [14:09<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 849.6029, 'train_samples_per_second': 15.654, 'train_steps_per_second': 0.247, 'train_loss': 0.526094118754069, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=210, training_loss=0.526094118754069, metrics={'train_runtime': 849.6029, 'train_samples_per_second': 15.654, 'train_steps_per_second': 0.247, 'train_loss': 0.526094118754069, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"output_dir\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_num_workers=4,\n",
    "    logging_steps=50,\n",
    "    seed=42,\n",
    "    group_by_length=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0521, -0.0423]])\n",
      "[[0.5235834  0.47641668]]\n",
      "0\n",
      "관련된 질문이 아닙니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/mckmtzyn7fs347mskkmmtgg40000gn/T/ipykernel_38671/2354807846.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pr = F.softmax(logits).numpy()\n",
      "/var/folders/k_/mckmtzyn7fs347mskkmmtgg40000gn/T/ipykernel_38671/2354807846.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(int(arg))\n",
      "/var/folders/k_/mckmtzyn7fs347mskkmmtgg40000gn/T/ipykernel_38671/2354807846.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  if int(arg) == 0 and (pr[0][0] >= 0.98).all():\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "text = \"이름이 'T'로 시작하는 쥬라기 시대의 공룡 종을 찾습니다.\"\n",
    "base_model = \"monologg/koelectra-small-v3-discriminator\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"WinF/stackorderflow-filter-v1\",\n",
    "    num_labels=2,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits.detach().cpu()\n",
    "pr = F.softmax(logits).numpy()\n",
    "arg = np.argmax(pr, axis=1)\n",
    "print(logits)\n",
    "print(pr)\n",
    "print(int(arg))\n",
    "if int(arg) == 0 and (pr[0][0] >= 0.98).all():\n",
    "    print(\"관련된 질문입니다.\")\n",
    "else:\n",
    "    print(\"관련된 질문이 아닙니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfn-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
